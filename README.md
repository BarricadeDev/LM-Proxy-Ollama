# LM-Proxy-Ollama
Converts the Github Copilot API Endpoints from LM Proxy into Ollama compatible ones therefore you can use the other models in Copilot Chat Such as GPT-4, GPT 4o Mini and GPT 3.5 Turbo if you want.
